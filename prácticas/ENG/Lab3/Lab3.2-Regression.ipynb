{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 3.2: Machine Learning (Regression)**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introduction**\n",
    "\n",
    "In the previous practice, we focused on solving problems where the goal was to predict a class based on an input (classification). \n",
    "\n",
    "To complete the *machine learning* diagram, specifically within the field of *supervised learning*, we still need to explore **regression problems**.\n",
    "\n",
    "<center><img src=\"ML_Diagram.png\" alt=\"diagram\" width=\"1000'/></center>\n",
    "\n",
    "As you know, in a regression problem, we aim to predict one or more **numerical values**. Similar to classification, solving supervised learning regression problems requires **labeled data**, meaning data where we already know the expected output or correct label for a given input.\n",
    "\n",
    "These data points will be used by the model to attempt to learn the *unknown formula* during training.\n",
    "\n",
    "### **Objective**\n",
    "In this practice, you will learn how to solve regression problems using different models and how to evaluate their performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **2. Exercise 1**\n",
    "\n",
    "We are asked to perform the following task:\n",
    "\n",
    "> Create a model that, given the time in the first sector `Sector1Time`, can predict the total lap time `LapTime`.    \n",
    "\n",
    "Let's reload our data and generate the necessary dataset to solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seed = 2533\n",
    "\n",
    "data = pd.read_pickle('https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'>\n",
    "    <b>Exercise:</b> Create a scatter plot to analyze the relationship between both variables.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Remove the <i>outlier</i> from the dataframe and generate the graph again. Given the new graph, would you say that the relationship between the variables is <strong>linear</strong> or <strong>non-linear</strong>?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the type of relationship, we will need to select different regression models.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    We cannot always visually analyze this relationship. In this case, we can because we only have two variables, but this is not usually possible.\n",
    "</div>\n",
    "\n",
    "### **Datasets**\n",
    "\n",
    "Regardless of the chosen model, just like in the classification section, it will be necessary to create a labeled dataset (with X and Y) and split it into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create the DataFrame <code>data_sector2lap</code> with the necessary columns to solve this problem. Convert the timedelta columns to float using <code>data[\"columnname\"].dt.total_seconds()</code>. Split the data into training and test sets (80/20), then <b>standardize</b> the X values.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the training and test data with the following plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(x = X_train.flatten(), y = Y_train, color = ('blue', 0.3), edgecolors = None, label = 'Train data')\n",
    "plot = sns.scatterplot(x = X_test.flatten(), y = Y_test, color = ('green', 0.8), edgecolors = None, label = 'Test data')\n",
    "plot.set_xlabel('Sector1Time')\n",
    "plot.set_ylabel('LapTime')\n",
    "plot.set_title('Visualization of Training and Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Baseline and Metrics**  \n",
    "Once the datasets have been created and preprocessed, we can proceed to solve the problem. Just like in classification problems, regression also has several **baselines**.\n",
    "\n",
    "The most commonly used is the `Mean` model, which simply always returns the mean of the training set's $Y$ values. There are also versions that use the median or predefined quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create and train a \"Mean\" baseline using the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html\"><code>DummyRegressor()</code></a> class from <i>scikit-learn</i>. Store the model in the variable <code>baseline_media</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the model, since we are working in 2D, we can represent it in the previous plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(x = X_train.flatten(), y = Y_train, color = ('blue', 0.3), edgecolors = None, label = 'Train data')\n",
    "sns.scatterplot(x = X_test.flatten(), y = Y_test, color = ('green', 0.8), edgecolors = None, label = 'Test data')\n",
    "plot = sns.lineplot(x = X_train.flatten(), y = baseline_media.predict(X_train), color = 'red', label = 'Baseline media')\n",
    "plot.set_xlabel('Sector1Time')\n",
    "plot.set_ylabel('LapTime')\n",
    "plot.set_title('Visualization of Test Data and Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the baseline does not fit the training data very well, so its performance will leave much to be desired.\n",
    "\n",
    "To quantify the predictive ability of the model, we will, just like in classification, obtain some **metrics**.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    Classification metrics cannot be used in regression problems. The former are designed to work with probabilities (values between 0 and 1), while regression metrics work with real numbers (values between -inf and inf).\n",
    "</div>\n",
    "\n",
    "For this type of problem, two main metrics are used, which are limited to calculating **the differences between the actual $Y$ values and the predicted values $\\hat{Y}$**. These are:\n",
    "* **MAE:** Mean Absolute Error, implemented in the method [`mean_absolute_error(Y_test, Y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error).\n",
    "\n",
    "* **MSE:** Mean Squared Error, implemented in the method [`mean_squared_error(Y_test, Y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error).\n",
    "\n",
    "* **$R^2$:** Coefficient of Determination, implemented in the method [`r2_score(Y_test, Y_pred)`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Since both <i>MAE</i> and <i>MSE</i> measure errors, they are better the smaller their value. The <i>Coefficient of Determination</i>, on the other hand, is better the closer it is to 1.</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Obtain the metrics mentioned above for the baseline on both the <i>training</i> and <i>test</i> sets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Other Models**\n",
    "\n",
    "As you can see, the results are far from ideal (as expected from the previous plot), so it is necessary to use more complex models that leverage the input data.\n",
    "\n",
    "In this practice, we will explore the following:\n",
    "\n",
    "* **Linear Regression:** Learns linear relationships between input and output variables.\n",
    "* **Polynomial Regression:** Extends linear regression by allowing non-linear relationships through the use of polynomials.\n",
    "* **K-Nearest Neighbors (KNN):** A regression algorithm that predicts the value of an instance based on the average of the values of its $k$ nearest neighbors.\n",
    "* **Decision Trees:** A regression model that creates a tree to predict a value based on the features of the data (inputs).\n",
    "* **SVR (Support Vector Regression):** The regression version of SVM. Like in classification, without kernel functions, it can only learn linear relationships. It aims to ensure that most examples are within the $e$-tube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Train a <i>Linear Regression</i> model (<code>model_linear</code>) and evaluate its performance on both the <i>training</i> and <i>test</i> sets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the learned model, we will plot the resulting model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(x = X_train.flatten(), y = Y_train, color = ('blue', 0.3), edgecolors = None, label = 'Train data')\n",
    "sns.scatterplot(x = X_test.flatten(), y = Y_test, color = ('green', 0.8), edgecolors = None, label = 'Test data')\n",
    "plot = sns.lineplot(x = X_train.flatten(), y = model_linear.predict(X_train), color = 'red', label = 'Linear Regression')\n",
    "plot.set_xlabel('Sector1Time')\n",
    "plot.set_ylabel('LapTime')\n",
    "plot.set_title('Model Fit to the Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model fits the training data much better, and as a result, it performs better with the test set.\n",
    "\n",
    "#### **Is it possible to improve the results even further?**\n",
    "\n",
    "Now, let's try to solve the problem using a non-linear method: **Polynomial Regression**.\n",
    "\n",
    "This model doesn't have a direct class in *Scikit-learn*, but we can use `PolynomialFeatures`. This class transforms our data into polynomial *features*.\n",
    "\n",
    "For example, if we have a single *feature* $x$ and choose a degree of 3, `PolynomialFeatures` will create two new *features*, $x^3$, $x^2$, and $x$.\n",
    "\n",
    "This allows us to fit a linear model to the transformed data, which is equivalent to fitting a polynomial model to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Transform the features into polynomial features\n",
    "poly = PolynomialFeatures(degree = 3) \n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Fit the linear regression model to the polynomial features\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_train_poly, Y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "print(mean_absolute_error(Y_train, model_poly.predict(X_train_poly)))\n",
    "print(mean_squared_error(Y_train, model_poly.predict(X_train_poly)))\n",
    "print(r2_score(Y_train, model_poly.predict(X_train_poly)))\n",
    "print('----')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(mean_absolute_error(Y_test, model_poly.predict(X_test_poly)))\n",
    "print(mean_squared_error(Y_test, model_poly.predict(X_test_poly)))\n",
    "print(r2_score(Y_test, model_poly.predict(X_test_poly)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the learned model, we will plot the resulting model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,8))\n",
    "sns.scatterplot(x = X_train.flatten(), y = Y_train, color = ('blue', 0.3), edgecolors = None, label = 'Train data')\n",
    "sns.scatterplot(x = X_test.flatten(), y = Y_test, color = ('green', 0.8), edgecolors = None, label = 'Test data')\n",
    "\n",
    "X_range = [[i/10] for i in range(-10, 41)]\n",
    "X_range_poly = poly.transform(X_range)\n",
    "y_range_pred = model_poly.predict(X_range_poly)\n",
    "plot = sns.lineplot(x = [x[0] for x in X_range], y = y_range_pred, color = 'red', label = 'Polynomial Regression')\n",
    "\n",
    "plot.set_xlabel('Sector1Time')\n",
    "plot.set_ylabel('LapTime')\n",
    "plot.set_title('Model Fit to the Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Train, evaluate, and plot a <i>Polynomial Regression</i> model (<code>model_poli_2</code>) with degree 10. Create new variables to avoid overwriting the previous model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, if we try to create a model that fits the training data too well, we fall into the so-called **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Train and evaluate the remaining models (<i>K-Nearest Neighbors</i>, <i>Decision Trees</i>, and <i>SVR</i>) using the following function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, Y_train, X_test, Y_test, model_name):\n",
    "    mae_train = mean_absolute_error(Y_train, model.predict(X_train))\n",
    "    mse_train = mean_squared_error(Y_train, model.predict(X_train))\n",
    "    r2_train = r2_score(Y_train, model.predict(X_train))\n",
    "    mae_test = mean_absolute_error(Y_test, model.predict(X_test))\n",
    "    mse_test = mean_squared_error(Y_test, model.predict(X_test))\n",
    "    r2_test = r2_score(Y_test, model.predict(X_test))\n",
    "    results = [model_name, mae_train, mse_train, r2_train, mae_test, mse_test, r2_test]\n",
    "    return results\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Baseline\n",
    "results_base = evaluate_model(baseline_media, X_train, Y_train, X_test, Y_test, 'Baseline')\n",
    "all_results.append(results_base)\n",
    "\n",
    "# Linear\n",
    "results_lineal = evaluate_model(model_linear, X_train, Y_train, X_test, Y_test, 'Linear')\n",
    "all_results.append(results_lineal)\n",
    "\n",
    "# Polinomial\n",
    "results_poly = evaluate_model(model_poly, X_train_poly, Y_train, X_test_poly, Y_test, 'Polynomial (3)')\n",
    "all_results.append(results_poly)\n",
    "\n",
    "# Your code here\n",
    "# The previous models are already trained, remember to train the new ones before passing them to the function\n",
    "\n",
    "# KNN\n",
    "\n",
    "# Decision Trees\n",
    "\n",
    "# SVR\n",
    "\n",
    "# Print the resulting dataframe\n",
    "multi_index = pd.MultiIndex.from_tuples([ ('Model', 'Name'), ('Train', 'MAE'), ('Train', 'MSE'), ('Train', 'R^2'), ('Test', 'MAE'), ('Test', 'MSE'), ('Test', 'R^2')])    \n",
    "all_results = pd.DataFrame(all_results, columns = multi_index)\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **3. Exercise 2**\n",
    "\n",
    "We are asked to perform the following task:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create a model capable of predicting, from <i>LapTime</i>, using <i>SpeedI1</i>, <i>SpeedI2</i>, <i>SpeedFL</i>, <i>SpeedST</i>, and <i>TyreLife</i>. Which model has the best results?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
