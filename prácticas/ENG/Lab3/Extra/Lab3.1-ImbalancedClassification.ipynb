{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extra 3.1: Imbalanced Classification**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introduction**\n",
    "In this additional practice, we are asked to:\n",
    "\n",
    "> Create a binary classifier that learns to predict whether a lap has been deleted or not.\n",
    "\n",
    "A lap is *\"deleted\"* when one of the drivers makes some type of irregularity during it, usually going beyond the track limits.\n",
    "\n",
    "Our goal is to detect these types of laps using only data on *average speeds* at the *finish line* and *maximum speed in the sector*.\n",
    "\n",
    "These speeds are typically altered when a driver does not comply with the sport regulations (exceeding limits, not respecting yellow flags, not reducing speed during the safety car, going too slow in exit or entry zones, etc.).\n",
    "\n",
    "**In the following block of code, we load the data and retrieve the \"Deleted\" column that was removed during the preprocessing in practice 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load files from Labs 2.2 and 3.1\n",
    "data_full = pd.read_csv('https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.csv')\n",
    "data_reduced = pd.read_pickle('https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl')\n",
    "\n",
    "# Merge missing columns without redundant rows\n",
    "data_full['Time'] = data_full['Time'].astype(str)\n",
    "data_reduced['Time'] = data_reduced['Time'].astype(str)\n",
    "cols_to_add = [col for col in data_full.columns if col not in data_reduced.columns]\n",
    "data = data_reduced.merge(data_full[['Time'] + cols_to_add], on = 'Time', how = 'left')\n",
    "data = data.dropna(subset = ['SpeedI1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Preprocessing and Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Create a new DataFrame <code>data_vel</code> with the relevant columns for our problem ( <i>\"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\" and \"Deleted\"<i>). To simplify, we will only keep the <b>Williams</b> and <b>Alpine</b> teams.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = ['Williams', 'Alpine']\n",
    "data_vel = data.loc[data['Team'].isin(teams), ['Team', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'Deleted']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Add the \"Class\" column to the DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vel['Class'] = data_vel['Deleted'].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Visualize the distribution of maximum speed in the sector (\"SpeedST\") for both teams.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# With a KDE\n",
    "plt.figure(figsize = (10, 4))\n",
    "sns.kdeplot(data = data_vel, x = 'SpeedST', hue = 'Team', fill = True)\n",
    "plt.title('Distribution by team')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Split the dataset into <code>data_vel_train</code> and <code>data_vel_test</code> using the <code>train_test_split</code> function. Use 30% for testing.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 2533\n",
    "data_vel_train, data_vel_test = train_test_split(data_vel, test_size = 0.30, random_state = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Baselines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Train the baselines <i>Random</i> and <i>Zero-R</i>. Remember to split the training data into X and Y first.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "X_train = data_vel_train[['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']]\n",
    "Y_train = data_vel_train['Class']\n",
    "\n",
    "baseline_random = DummyClassifier(strategy = 'uniform', random_state = seed)\n",
    "baseline_zeror = DummyClassifier(strategy = 'most_frequent')\n",
    "\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "baseline_zeror.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Split the test data into X and Y and make predictions with each model (<code>pred_random</code> and <code>pred_zeror</code>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_vel_test[['SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST']]\n",
    "Y_test = data_vel_test['Class']\n",
    "\n",
    "pred_aleatorio = baseline_random.predict(X_test)\n",
    "pred_zeror = baseline_zeror.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our models trained and have made predictions on the test set, so let's move on to evaluating their performance in a more objective way.\n",
    "\n",
    "For this, we will once again use the **\"metrics\"** module from the **\"scikit-learn\"** library.\n",
    "\n",
    "Remember that the most relevant metrics in classification problems are the following:\n",
    "\n",
    "<div style=\"width:800px;background:white;padding:10px\">\n",
    "    <img src=\"https://i.imgur.com/7WwY9bZ.jpeg\" style=\"margin-bottom:10px\"> </img>\n",
    "</div>\n",
    "\n",
    "For our specific problem, they would mean the following:\n",
    "\n",
    "* **Accuracy:** The percentage of correct predictions over the total number of predictions. Useful when the classes are balanced.\n",
    "* **Precision:** Of all the times the model predicted a 1 (deleted), how many times was it correct?\n",
    "* **Recall:** Of all the laps that were actually deleted, how many did the model successfully detect?\n",
    "* **F1-Score:** The \"harmonic\" mean between Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Use the functions from <code>sklearn.metrics</code> to evaluate the <i>Random</i> and <i>Zero-R</i> models. Obtain <i>Accuracy</i>, <i>Precision</i>, <i>Recall</i>, and <i>F1-score</i> metrics, as well as the <i>Confusion Matrix</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('-' * 50)\n",
    "print('Random')\n",
    "print('-' * 50)\n",
    "print('· Confusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_test, pred_aleatorio))\n",
    "print('· Accuracy:', metrics.accuracy_score(Y_test, pred_aleatorio))\n",
    "print('· Precision:', metrics.precision_score(Y_test, pred_aleatorio))\n",
    "print('· Recall:', metrics.recall_score(Y_test, pred_aleatorio))\n",
    "print('· F1 Score:', metrics.f1_score(Y_test, pred_aleatorio))\n",
    "print()\n",
    "print('-' * 50)\n",
    "print('Zero-R')\n",
    "print('-' * 50)\n",
    "print('· Confusion matrix:')\n",
    "print(metrics.confusion_matrix(Y_test, pred_zeror))\n",
    "print('· Accuracy:', metrics.accuracy_score(Y_test, pred_zeror))\n",
    "print('· Precision:', metrics.precision_score(Y_test, pred_zeror))\n",
    "print('· Recall:', metrics.recall_score(Y_test, pred_zeror))\n",
    "print('· F1 Score:', metrics.f1_score(Y_test, pred_zeror))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained, except for Accuracy, leave much to be desired.\n",
    "\n",
    "As you may remember, Accuracy is not a good metric when we are dealing with a **class imbalance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Obtain the number of examples of each class (positive and negative) in the <code>data_vel</code> set without splitting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vel.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This imbalance occurs because there are many more \"normal\" laps (class $0$) than \"eliminated\" laps (class $1$).\n",
    "Therefore, we cannot rely on accuracy and will need to learn a different model that maximizes:\n",
    "\n",
    "- **Recall**, to avoid false negatives (eliminated laps that the model did not detect).\n",
    "- **Precision**, to avoid false positives (normal laps that the model classifies as eliminated).\n",
    "- **F1-score**, if we are interested in balancing the two mentioned metrics.\n",
    "\n",
    "Now we will try to train more complex models in order to improve these metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following models we are going to learn, unlike the baselines, do use the input data ($X$) to predict the outputs ($Y$); therefore, from now on, it is crucial to standardize this data.\n",
    "\n",
    "Remember that this helps to avoid variables measured on larger scales from dominating those measured on smaller scales, which would slow down the learning of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\"><code>StandardScaler()</code></a> from <i>sklearn</i> to standardize the train and test X data. Store the new data in <code>X_train_std</code> and <code>X_test_std</code>.\n",
    "    <hr>\n",
    "    Remember that the test data is unknown to us, so it cannot influence the calculation of the mean and standard deviation.\n",
    "    <hr>\n",
    "    How to use <code>StandardScaler()</code>:\n",
    "    <ul>\n",
    "        <li> <code>fit_transform(X_train)</code>: This should only be done with the training data. This method performs two steps: it obtains the means and standard deviations of each column (<code>fit()</code>) and standardizes based on them (<code>transform()</code>).</li>\n",
    "        <li> <code>transform(X_test)</code>: It uses the means and standard deviations calculated from the train set (with <code>fit()</code>) to standardize.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print(X_train_std.mean(axis = 0))\n",
    "print(X_train_std.std(axis = 0))\n",
    "\n",
    "print(X_test_std.mean(axis = 0))\n",
    "print(X_test_std.std(axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Train various models using the functions defined previously in practice 3.1.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_model(model_name, model, X_train_std, Y_train, X_test_std, Y_test):\n",
    "    # Train the model\n",
    "    model.fit(X_train_std, Y_train.squeeze())\n",
    "    # Predictions\n",
    "    Y_train_pred = model.predict(X_train_std)\n",
    "    Y_test_pred = model.predict(X_test_std)\n",
    "    # Calculate metrics for train\n",
    "    tr_accuracy = metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "    tr_precision = metrics.precision_score(Y_train, Y_train_pred, zero_division  =0)\n",
    "    tr_recall = metrics.recall_score(Y_train, Y_train_pred)\n",
    "    tr_f1 = metrics.f1_score(Y_train, Y_train_pred)\n",
    "    \n",
    "    # Calculate metrics for test\n",
    "    tst_accuracy = metrics.accuracy_score(Y_test, Y_test_pred)\n",
    "    tst_precision = metrics.precision_score(Y_test, Y_test_pred, zero_division = 0)\n",
    "    tst_recall = metrics.recall_score(Y_test, Y_test_pred)\n",
    "    tst_f1 = metrics.f1_score(Y_test, Y_test_pred)\n",
    "    return (model_name, tr_accuracy, tr_precision, tr_recall, tr_f1, tst_accuracy, tst_precision, tst_recall, tst_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def train_and_eval(X_train_std, Y_train, X_test_std, Y_test):\n",
    "    # Create a list to store the results of each model\n",
    "    all_results = []\n",
    "    \n",
    "    # Random baseline\n",
    "    the_model = DummyClassifier(strategy = 'uniform', random_state=seed)\n",
    "    model_results = train_and_eval_model('Random', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Zero-R baseline\n",
    "    the_model = DummyClassifier(strategy = 'most_frequent')\n",
    "    model_results = train_and_eval_model('Zero-R', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Logistic Regression baseline\n",
    "    the_model = LogisticRegression()\n",
    "    model_results = train_and_eval_model('Log. Reg.', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # KNN baseline\n",
    "    the_model = KNeighborsClassifier(n_neighbors = 3)\n",
    "    model_results = train_and_eval_model('KNN', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Decision Tree baseline\n",
    "    the_model = DecisionTreeClassifier(random_state = seed, max_depth = 2)\n",
    "    model_results = train_and_eval_model('Tree', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Linear SVM baseline\n",
    "    the_model = SVC(kernel = 'linear')\n",
    "    model_results = train_and_eval_model('Linear SVM', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Polynomial SVM baseline\n",
    "    the_model = SVC(kernel = 'poly', degree = 2, coef0 = 1)\n",
    "    model_results = train_and_eval_model('Poly SVM', the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    \n",
    "    # Print the resulting dataframe\n",
    "    multi_index = pd.MultiIndex.from_tuples([('Model', 'Name'), ('Train', 'Accuracy'), ('Train', 'Precision'), ('Train', 'Recall'), ('Train', 'F1'), ('Test', 'Accuracy'), ('Test', 'Precision'), ('Test', 'Recall'), ('Test', 'F1')])    \n",
    "    all_results = pd.DataFrame(all_results, columns = multi_index)\n",
    "    display(all_results)\n",
    "\n",
    "train_and_eval(X_train_std, Y_train, X_test_std, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Analysis of Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the reasons for its poor performance?**\n",
    "\n",
    "With such a class imbalance, the models **learn to predict only the majority class (0)**, generating high Accuracy values but low Precision, Recall, and F1 scores. \n",
    "\n",
    "This explains the poor performance in metrics relevant to the positive class, despite an acceptable Accuracy.\n",
    "\n",
    "The decision tree stands out a bit, attempting to detect positives in training, although unsuccessfully in the test.\n",
    "\n",
    "No other model correctly detects the positive class. Logistic Regression, KNN, or SVM have null recall and F1 scores, predicting only the majority class.\n",
    "\n",
    "Another factor that might be affecting performance is the insufficiency of the input data ($X$). We may need to add another column from our dataset as input to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Exercise:</b> Modify a hyperparameter of the best model to try to improve its result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(X_train_std, Y, X_test_std, Y_test):\n",
    "    # Create a list to store the results of each model\n",
    "    all_results = []\n",
    "\n",
    "    # Baseline Tree (we set class_weight balanced, we can try with more depth)\n",
    "    the_model = DecisionTreeClassifier(random_state = seed, max_depth = 3, class_weight = 'balanced', min_samples_split = 4, min_samples_leaf = 2)\n",
    "    model_results = train_and_eval_model('Tree', the_model, X_train_std, Y, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Print the resulting dataframe\n",
    "    multi_index = pd.MultiIndex.from_tuples([ ('Model', 'Name'), ('Train', 'Accuracy'), ('Train', 'Precision'), ('Train', 'Recall'), ('Train', 'F1'), ('Test', 'Accuracy'), ('Test', 'Precision'), ('Test', 'Recall'), ('Test', 'F1') ])    \n",
    "    all_results = pd.DataFrame(all_results, columns = multi_index)\n",
    "    display(all_results)\n",
    "\n",
    "train_and_eval(X_train_std, Y_train, X_test_std, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, even by changing the hyperparameters, the difference between the classes is so exaggerated that it makes it impossible for the model to perform well.\n",
    "\n",
    "One possible solution in this case would be the previously mentioned inclusion of an additional column (perhaps the lap or sector times might help us), or simply applying an **oversampling** strategy.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Oversampling:</strong> A technique to balance the number of examples in each class by repeating the minority samples.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
