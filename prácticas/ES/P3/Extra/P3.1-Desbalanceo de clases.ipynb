{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extra 3.1: Clasificación desbalanceada**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introducción**\n",
    "En esta práctica adicional se nos pide:\n",
    "\n",
    "> Crear un clasificador binario que aprenda a predecir si una vuelta ha sido eliminada o no.  \n",
    "\n",
    "Una vuelta es *\"eliminada\"* cuando uno de los pilotos comete algún tipo de irregularidad durante la misma, normalmente saltarse los límites de la pista.\n",
    "\n",
    "Nuestro objetivo es poder detectar este tipo de vueltas utilizando únicamente datos de *velocidades medias* en la *línea de meta* y *máxima en el sector*. \n",
    "\n",
    "Estas velocidades normalmente se ven alteradas cuando un piloto no cumple con el reglamento deportivo (exceder límites, no respetar banderas amarillas, no reducir la velocidad del safety car, ir demasiado lento en zonas de salida o de entrada...).\n",
    "\n",
    "**En el siguiente bloque de código cargamos los datos y recuperamos la columna \"Deleted\" eliminada durante el preprocesamiento de la práctica 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar archivos de las practicas 2.2 y 3.1\n",
    "data_full = pd.read_csv(\"https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.csv\")\n",
    "data_reduced = pd.read_pickle(\"https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl\")\n",
    "\n",
    "#Fusionar columnas faltantes sin las filas redundantes\n",
    "data_full[\"Time\"] = data_full[\"Time\"].astype(str)\n",
    "data_reduced[\"Time\"] = data_reduced[\"Time\"].astype(str)\n",
    "cols_to_add = [col for col in data_full.columns if col not in data_reduced.columns]\n",
    "data = data_reduced.merge( data_full[[\"Time\"] + cols_to_add], on=\"Time\", how=\"left\" )\n",
    "data = data.dropna(subset=[\"SpeedI1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Preprocesamiento y visualización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea un nuevo DataFrame <code>data_vel</code> con las columnas relevantes para nuestro problema ( <i>\"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\" y \"Deleted\"<i>). Por simplificar, nos quedamos solo con los equipos <b>Williams</b> y <b>Alpine</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equipos = [\"Williams\", \"Alpine\"]\n",
    "data_vel = data.loc[data[\"Team\"].isin(equipos), [\"Team\", \"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\", \"Deleted\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Añade la columna \"Class\" al DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vel[\"Class\"] = data_vel[\"Deleted\"].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Visualiza la distribución de velocidad máxima en el sector (\"SpeedST\") para ambos equipos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Con un KDE\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.kdeplot(data=data_vel, x=\"SpeedST\", hue=\"Team\", fill=True)\n",
    "plt.title(\"Distribución por equipo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa el conjunto en <code>data_vel_train</code> y <code>data_vel_test</code> utilizando la función <code>train_test_split</code>. Utiliza el 30% para test.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 2533\n",
    "data_vel_train, data_vel_test = train_test_split(data_vel, test_size=0.30, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Baselines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Entrena los baselines <i>Aleatorio</i> y <i>Zero-R</i>. Recuerda separar previamente la X e Y de entrenamiento.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "X_train = data_vel_train[[\"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\"]]\n",
    "Y_train = data_vel_train[\"Class\"]\n",
    "\n",
    "baseline_aleatorio = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "baseline_zeror = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "baseline_aleatorio.fit(X_train, Y_train)\n",
    "baseline_zeror.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa la X e Y de test y realiza una predicción con cada modelo (<code>pred_aleatorio</code> y <code>pred_zeror</code>) .\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_vel_test[[\"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\"]]\n",
    "Y_test = data_vel_test[\"Class\"]\n",
    "\n",
    "pred_aleatorio = baseline_aleatorio.predict(X_test)\n",
    "pred_zeror = baseline_zeror.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestros modelos entrenados y hemos realizado predicciones sobre el conjunto de test, así que ahora pasamos a evaluar su rendimiento de forma un poco más objetiva.\n",
    "\n",
    "Para ello utilizaremos de nuevo el módulo **\"metrics\"** de la librería **\"scikit-learn\"**.\n",
    "\n",
    "Recueda que las métricas más relevantes en problemas de clasificación son las siguientes:\n",
    "\n",
    "<div style=\"width:800px;background:white;padding:10px\">\n",
    "    <img src=\"https://i.imgur.com/7WwY9bZ.jpeg\" style=\"margin-bottom:10px\"> </img>\n",
    "</div>\n",
    "\n",
    "Para nuestro problema concreto significarían lo siguiente:\n",
    "\n",
    "* **Accuracy:** Porcentaje de aciertos del modelo sobre el total de predicciones. Útil cuando las clases están balanceadas.\n",
    "* **Precision:** De todas las veces que el modelo predijo un 1 (deleted), ¿Cuántas veces acertó?\n",
    "* **Recall:** De todas las vueltas que fueron realmente eliminadas, ¿Cuántas fue capaz de detectar el modelo?\n",
    "* **F1-Score:** Media \"armónica\" entre Precision y Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Utiliza las funciones de <code>sklearn.metrics</code> para evaluar los modelos <i>Aleatorio</i> y <i>Zero-R</i>. Obtén métricas <i>Accuracy</i>, <i>Precision</i>, <i>Recall</i> y <i>F1-score</i> así como la <i>Matriz de confusión</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Aleatorio\")\n",
    "print(\"-\"*50)\n",
    "print(\"· Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(Y_test, pred_aleatorio))\n",
    "print(\"· Accuracy:\", metrics.accuracy_score(Y_test, pred_aleatorio))\n",
    "print(\"· Precision:\", metrics.precision_score(Y_test, pred_aleatorio))\n",
    "print(\"· Recall:\", metrics.recall_score(Y_test, pred_aleatorio))\n",
    "print(\"· F1 Score:\", metrics.f1_score(Y_test, pred_aleatorio))\n",
    "print()\n",
    "print(\"-\"*50)\n",
    "print(\"Zero-R\")\n",
    "print(\"-\"*50)\n",
    "print(\"· Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(Y_test, pred_zeror))\n",
    "print(\"· Accuracy:\", metrics.accuracy_score(Y_test, pred_zeror))\n",
    "print(\"· Precision:\", metrics.precision_score(Y_test, pred_zeror))\n",
    "print(\"· Recall:\", metrics.recall_score(Y_test, pred_zeror))\n",
    "print(\"· F1 Score:\", metrics.f1_score(Y_test, pred_zeror))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos, salvo en la Accuracy, dejan mucho que desear.\n",
    "\n",
    "Como recordarás, la Accuracy no es una buena métrica cuando nos encontramos ante un conjunto con **desbalanceo de clases**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Obtén el número de ejemplos de cada clase (positivo y negativo) en el conjunto <code>data_vel</code> sin dividir.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vel.groupby(\"Class\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este desbalance se produce porque hay muchas más vueltas \"normales\" (clase $0$) que vueltas \"eliminadas\" (clase $1$).\n",
    "Por tanto no podemos fijarnos en la accuracy y tendremos que aprender algún modelo diferente que maximice:\n",
    "\n",
    "- El **Recall**, para evitar los falsos negativos (vueltas eliminadas que el modelo no detectó).\n",
    "- La **Precision**, para evitar los falsos positivos (vueltas normales que el modelo clasifica como eliminadas.).\n",
    "- El **F1-score**, si nos interesa un equilibrio entre las dos anteriores.\n",
    "\n",
    "Probaremos a entrenar ahora modelos más complejos a fin de mejorar estas métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Aprendizaje**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los siguientes modelos que vamos a aprender, a diferencia de los baselines, sí utilizan los datos de entrada ($X$) para predecir las salidas ($Y$); por tanto, a partir de ahora es crucial estandarizar estos datos.\n",
    "\n",
    "Recuerda que esto nos sirve para evitar que las variables que se miden en escalas más grandes dominen a las que se miden en escalas más pequeñas, lo que ralentizaría el aprendizaje de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Utiliza el <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\"><code>StandardScaler()</code></a> de <i>sklearn</i> para estandarizar las X de train y de test. Almacena los nuevos datos en <code>X_train_std</code> y <code>X_test_std</code>. \n",
    "    <hr>\n",
    "    Recuerda que los datos de test son desconocidos para nosotros, por lo que no pueden influir a la hora de calcular la media y las desviación. \n",
    "    <hr>\n",
    "    Cómo utilizar el <code>StandardScaler()</code>:\n",
    "    <ul>\n",
    "        <li> <code>fit_transform(X_train)</code>: Solo debe hacerse con los datos de entrenamiento. Este método hace dos pasos: obtiene las medias y desviaciones de cada columna (<code>fit()</code>) y estandariza en base a ellas (<code>transform()</code>) .</li>\n",
    "        <li> <code>transform(X_test)</code>: Utiliza las medias y desviaciones calculadas en el conjunto de train (con el <code>fit()</code>) para estandarizar.</li>\n",
    "    </ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print(X_train_std.mean(axis=0))\n",
    "print(X_train_std.std(axis=0))\n",
    "\n",
    "print(X_test_std.mean(axis=0))\n",
    "print(X_test_std.std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Entrena diversos modelos aprovechando las funciones definidas previamente en la práctica 3.1.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval_model(model_name, model, X_train_std, Y_train, X_test_std, Y_test):\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train_std, Y_train.squeeze())\n",
    "    # Predicciones\n",
    "    Y_train_pred = model.predict(X_train_std)\n",
    "    Y_test_pred = model.predict(X_test_std)\n",
    "    # Calcular métricas para train\n",
    "    tr_accuracy = metrics.accuracy_score(Y_train, Y_train_pred)\n",
    "    tr_precision = metrics.precision_score(Y_train, Y_train_pred, zero_division=0)\n",
    "    tr_recall = metrics.recall_score(Y_train, Y_train_pred)\n",
    "    tr_f1 = metrics.f1_score(Y_train, Y_train_pred)\n",
    "    \n",
    "    # Calcular métricas para test\n",
    "    tst_accuracy = metrics.accuracy_score(Y_test, Y_test_pred)\n",
    "    tst_precision = metrics.precision_score(Y_test, Y_test_pred, zero_division=0)\n",
    "    tst_recall = metrics.recall_score(Y_test, Y_test_pred)\n",
    "    tst_f1 = metrics.f1_score(Y_test, Y_test_pred)\n",
    "    return (model_name, tr_accuracy, tr_precision, tr_recall, tr_f1, tst_accuracy, tst_precision, tst_recall, tst_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def train_and_eval(X_train_std, Y_train, X_test_std, Y_test):\n",
    "    # Creamos una lista donde almacenar los resultados de cada modelo\n",
    "    all_results = []\n",
    "    \n",
    "    # Baseline aleatorio\n",
    "    the_model = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "    model_results = train_and_eval_model(\"Aleatorio\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Baseline Zero-R\n",
    "    the_model = DummyClassifier(strategy=\"most_frequent\")\n",
    "    model_results = train_and_eval_model(\"Zero-R\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Baseline Log. Reg\n",
    "    the_model = LogisticRegression()\n",
    "    model_results = train_and_eval_model(\"Log. Reg.\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Baseline KNN\n",
    "    the_model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model_results = train_and_eval_model(\"KNN\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Baseline Tree\n",
    "    the_model =DecisionTreeClassifier(random_state=seed, max_depth=2)\n",
    "    model_results = train_and_eval_model(\"Tree\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Baseline SVM Lineal\n",
    "    the_model =  SVC(kernel='linear')\n",
    "    model_results = train_and_eval_model(\"SVM Lineal\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Baseline SVM polinómico\n",
    "    the_model =  SVC(kernel='poly', degree=2, coef0=1)\n",
    "    model_results = train_and_eval_model(\"SVM poli.\", the_model, X_train_std, Y_train, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    \n",
    "    # Imprimir el dataframe resultante\n",
    "    multi_index = pd.MultiIndex.from_tuples([ (\"Modelo\", \"Nombre\"), (\"Train\", \"Accuracy\"), (\"Train\", \"Precision\"), (\"Train\", \"Recall\"), (\"Train\", \"F1\"), (\"Test\", \"Accuracy\"), (\"Test\", \"Precision\"), (\"Test\", \"Recall\"), (\"Test\", \"F1\") ])    \n",
    "    all_results = pd.DataFrame(all_results, columns=multi_index)\n",
    "    display(all_results)\n",
    "\n",
    "train_and_eval(X_train_std, Y_train, X_test_std, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Análisis de resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuáles son las razones de su bajo rendimiento?**\n",
    "\n",
    "Con un desbalance de clases de esta magnitud, los modelos **aprenden a predecir solo la clase mayoritaria (0)**, generando altos valores de Accuracy pero bajos de Precision, Recall y F1. \n",
    "\n",
    "Esto explica el rendimiento pobre en métricas relevantes para la clase positiva, a pesar de una Accuracy aceptable.\n",
    "\n",
    "El árbol de decisión destaca un poco, intentando detectar positivos en entrenamiento, aunque sin éxito en el test.\n",
    "\n",
    "Ningún otro modelo detecta la clase positiva correctamente. Regresión Logística, KNN o SVM tienen recall y F1-score nulos, prediciendo solo la clase mayoritaria.\n",
    "\n",
    "Otro factor que podría estar afectando al rendimiento es la insuficiencia de los datos en la entrada ($X$). Puede que necesitemos añadir alguna columna más de nuestro dataset como entrada para mejorar el rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Modifica algún hiperparámetro del mejor modelo buscando mejorar su resultado.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(X_train_std, Y, X_test_std, Y_test):\n",
    "    # Creamos una lista donde almacenar los resultados de cada modelo\n",
    "    all_results = []\n",
    "\n",
    "    # Baseline Tree (le ponemos class_weight balanced, podemos probar con más depth)\n",
    "    the_model =DecisionTreeClassifier(random_state=seed, max_depth=3, class_weight='balanced', min_samples_split=4,  min_samples_leaf=2)\n",
    "    model_results = train_and_eval_model(\"Tree\", the_model, X_train_std, Y, X_test_std, Y_test)\n",
    "    all_results.append(model_results)\n",
    "    \n",
    "    # Imprimir el dataframe resultante\n",
    "    multi_index = pd.MultiIndex.from_tuples([ (\"Modelo\", \"Nombre\"), (\"Train\", \"Accuracy\"), (\"Train\", \"Precision\"), (\"Train\", \"Recall\"), (\"Train\", \"F1\"), (\"Test\", \"Accuracy\"), (\"Test\", \"Precision\"), (\"Test\", \"Recall\"), (\"Test\", \"F1\") ])    \n",
    "    all_results = pd.DataFrame(all_results, columns=multi_index)\n",
    "    display(all_results)\n",
    "\n",
    "train_and_eval(X_train_std, Y_train, X_test_std, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, incluso al variar con los hiperparámetros, la diferencia entre las clases es tan exagerada que hace imposible que el modelo tenga un buen rendimiento.\n",
    "\n",
    "Una posible solución en este caso sería la ya mencionada inclusión de alguna columna adicional (puede que los tiempos por vuelta o sector nos ayuden) o simplemente realizar alguna estrategia de **oversampling**.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Oversampling:</strong> Técnica para equilibrar el número de ejemplos de cada clase mediante la repetición de las muestras minoritarias.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
