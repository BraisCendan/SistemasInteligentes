{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 4.3: Redes neuronales convolucionales (CNN)**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introducción**\n",
    "\n",
    "Las redes neuronales que hemos considerado hasta ahora siempre han trabajado con *datos estructurados*, es decir, datos que pueden almacenarse en tablas. Actualmente, es cada vez más común enfrentarse a problemas que requieren el manejo de **datos no estructurados**, como imágenes, texto o audio, siendo las imágenes el tipo de dato más frecuente. En este tipo de problemas, a diferencia de los que hemos visto hasta ahora, las entradas del modelo no son vectores de valores extraídos de un conjunto de datos, sino imágenes.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Las imágenes en escala de grises se codifican como <b>matrices</b> bidimensionales, mientras que las imágenes a color se representan mediante <b>tensores</b> tridimensionales.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:1200px\">\n",
    "        <img src=\"https://i.imgur.com/urLXh6F.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "Los modelos que hemos visto hasta ahora están pensados para trabajar con vectores, por lo que no pueden trabajar con las imágenes directamente. Si quisiesemos utilizar un modelo clásico (como regresión logística o SVM) con imágenes, sería necesario transformar la imagen en un vector. Una forma común de hacerlo es *aplanar* la imagen. Aplanar una imagen significa convertir la matriz 2D (o tensor 3D) en un vector unidimensional concatenando las filas (o canales de color) de la imagen una tras otra. \n",
    "\n",
    "Por ejemplo, una imagen de $28\\times28$ píxeles se transformaría en un vector de $784$ elementos. Este vector resultante ya se podría utilizar como entrada para un modelo clásico. Aunque este método puede implicar la pérdida de información espacial relevante de la imagen original, representa una manera sencilla de adaptar modelos clásicos al procesamiento de imágenes. En redes tradicionales con capas densas (fully connected), como las que hemos visto hasta ahora, sería necesario realizar el mismo proceso. Esto implica que, incluso para imágenes pequeñas como la del ejemplo, se obtienen vectores de gran tamaño, lo que requiere aprender una gran cantidad de pesos o parámetros.\n",
    "\n",
    "Buscando solucionar estos problemas surgen las **redes neuronales convolucionales (CNN)**, cuya arquitectura se compone de dos partes:\n",
    "\n",
    "* **Extractor de características**: Esta parte se encarga de extraer las características relevantes de la imagen, es decir, aprende un vector de poca dimensión que representa a la imagen. Se compone de una serie de capas **convolucionales** y capas de **pooling**. \n",
    "* **Parte totalmente conectada**: Esta parte se encarga de resolver, a partir del vector aprendido, el problema que se pretende solventar (clasificación, regresión, ...). Está compuesta por una serie de capas densas (fully connected), como las redes utilizadas previamente.\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:1200px\">\n",
    "        <img src=\"https://i.imgur.com/vsSJBcu.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> La <i>parte convolucional</i> o el <i>extractor de carácteristicas</i> de una CNN es la encargada de aprender una <b>representación vectorial</b> de la imagen que luego será la entrada de la parte totalmente conectada encargada de realizar la predicción final.\n",
    "</div>\n",
    "\n",
    "\n",
    "### **Objetivo**\n",
    "En esta práctica aprenderás a resolver un problema de clasificación de imágenes creando una red convolucional con `tensorFlow` y `keras`.\n",
    "\n",
    "## **2. Configurar GPU**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder acelerar el entrenamiento lo máximo posible, en esta práctica haremos uso de las *GPUs* instaladas en los ordenadores de prácticas.\n",
    "\n",
    "Hasta ahora, todos los modelos que hemos entrenado se han ejecutado en *CPU* puesto que `tensorflow` ejecuta en este dispositivo por defecto. Esta librería, solo permite el uso de *GPU* en Windows mediante **Windows Subsystem for Linux (WSL)**.\n",
    "\n",
    "Esta característica nos permite tener un environment Linux directamente en Windows sin la necesidad de crear una máquina virtual o configurar un arranque dual. Como verás, podremos ejecutar programas de línea de comandos de Linux directamente en Windows.\n",
    "\n",
    "##### **Activar e instalar WSL**\n",
    "\n",
    "Tendrás que abrir una ventana de comandos `cmd.exe` y ejecutar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsl --install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indica tu **UO** como usuario y también como contraseña.\n",
    "\n",
    "Dentro de la consola de Linux (Ubuntu por defecto) tendremos que instalar el `conda` y crear el environment de la asignatura.\n",
    "\n",
    "##### **Instalar conda**\n",
    "\n",
    "Descargamos `miniconda` (versión reducida de `conda`) e instalamos.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Tendrás que decir que si (Yes) a la pregunta <i>Do you wish to update your shell profile to automatically initialize conda?</i>.</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -o Miniconda3-latest-Linux-x86_64.sh\n",
    "bash Miniconda3-latest-Linux-x86_64.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cierra el terminal WSL y vuelve a abrirlo para que actualize las variables del entorno.\n",
    "\n",
    "Puedes encontrarlo de nuevo en el menú de Windows buscando `WSL`.\n",
    "\n",
    "A continuación creamos de nuevo el environment `SSII`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create --name \"SSII\" python=3.10\n",
    "conda activate \"SSII\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalamos dentro del environment las librerías necesarias, incluyendo la versión de `tensorflow` con soporte de GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ipykernel pandas seaborn scikit-learn\n",
    "pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Visual Studio Code**\n",
    "\n",
    "En este momento tenemos dos sistemas operativos, el Windows nativo y un Linux que se ejecuta dentro del mismo. Nuestro objetivo será ejecutar este Notebook dentro del Linux.\n",
    "\n",
    "Para ello tendremos que indicar al Visual Studio Code, **que se conencte a una máquina diferente**. La forma más sencilla de hacerlo es:\n",
    "\n",
    "* Abre una nueva ventana de VSCode (`File > New Window`).\n",
    "* En la nueva ventana de VSCode, abajo a la izquierda aparece un icono de dos flechas enfrentadas.\n",
    "* Al hacer click nos aparece un menú superior, en este seleccionamos <i>Connect to WSL</i>.\n",
    "* Si todo funciona, Abajo a la izquierda aparecerá algo como **WSL: Ubuntu**.\n",
    "\n",
    "Lo siguiente será instalar las **extensiones de VSCode**. Ya las habías instalado en Windows, pero ahora tendrás que hacerlo en la distribución Linux.\n",
    "\n",
    "* Instala *Python* y *Jupyter*.\n",
    "\n",
    "##### **Sistema de archivos**\n",
    "\n",
    "Recuerda que ahora estamos dentro de otra máquina, por tanto tendremos que almacenar los notebooks de las prácticas dentro de la misma.\n",
    "\n",
    "Windows nos simplifica mucho este acceso, si abres un explorador de archivos, simplemente tendrás que ir a la carpeta *Linux* que aparece en los accesos directos de la izquierda:\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:600px\">\n",
    "        <img src=\"https://i.imgur.com/dEqSKsg.png\" style=\"height:400px\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "* Crea la carpeta `SSII` en `Linux/Ubuntu/home/**tu UO**/`.\n",
    "* Copia este notebook dentro de la misma.\n",
    "* Abre esa carpeta desde VSCode (`File > Open Folder...`).\n",
    "* Abre el notebook y selecciona como kernel el environment `conda` que acabas de crear.\n",
    "\n",
    "La forma más sencilla de verificar que `tensorflow` tiene acceso a la GPU es ejecutar el siguiente código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export TF_CPP_MIN_LOG_LEVEL=2  # Para que tensorflow muestre solo advertencias y errores\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 2533\n",
    "\n",
    "print(\"-\"*50)\n",
    "print(\"Num GPUs disponibles: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También puedes revisar el uso de GPU en el momento actual con el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si prefieres monitorizar el uso de GPU de forma constante, puedes abrir una terminal de WSL (desde Windows o desde el VScode en `Terminal > New terminal`) y ejecutar el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! watch -n1 nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplemente ejecuta el comando anterior cada 1 segundo. Para salir tendrás que pulsar `Ctrl+C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **3. Redes convolucionales**\n",
    "\n",
    "Una vez tenemos todo configurado vamos a proponer un posible problema.\n",
    "\n",
    "Imagina que trabajas para el servicio de informática de Correos, y que en la actualidad tienen a una persona encargada de leer manualmente los destinatarios de las cartas (escritos a mano) y ubicarlas, en función del código postal, en una caja u otra.\n",
    "\n",
    "Como ves, este proceso es muy lento, por lo que proponen instalar una cámara que tome imágenes de cada una de las cartas y que automáticamente lea los códigos postales. \n",
    "\n",
    "Ya poseen imágenes de los códigos postales de las cartas, pero no saben como extraer los dígitos de cada imagen, por tanto te plantean el siguiente problema:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Crear un modelo que, dada una imagen de un número escrito a mano, sea capaz de reconocer de que número se trata.</b> \n",
    "</div>\n",
    "\n",
    "### **3.1 Preprocesamiento de datos**\n",
    "\n",
    "Para ayudarte, ya se han encargado de crear manualmente un dataset que contiene imágenes de dígitos individuales y etiquetas indicando el número que aparece en la imagen.\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:1000px\">\n",
    "        <img src=\"https://i.imgur.com/cHlLRXB.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "Puedes descargar el conjunto mediante el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este dataset contiene $70000$ imágenes en escala de grises de $28\\times28$ de números del $0$ a $10$ escritos a mano. \n",
    "\n",
    "Como puedes apreciar, ya viene dividido en $X$, $Y$ así como en entrenamiento ($60000$) y test ($10000$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar, vamos a quedarnos solo con 20.000 ejemplos aleatorios de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(seed)\n",
    "indices = np.random.choice(len(x_train), size=20000, replace=False)\n",
    "\n",
    "# Obtener las muestras\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Normaliza los datos manualmente entre 0 y 1.\n",
    "    <hr>\n",
    "    Las clases del <code>scikit-learn</code> no funcionan en este caso, puesto que están pensadas para tratar con vectores. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un gráfico para ver uno de los ejemplos del conjunto de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_train[0], cmap=\"Greys\")\n",
    "plt.title(f\"Ejemplo de imagen del dígito {y_train[1]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Visualiza la imagen 1523 del conjunto de test. Añade su etiqueta (clase) real en el título.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2 Aprendizaje automático**\n",
    "\n",
    "Recuerda que para abordar este problema con modelos de aprendizaje clásico, necesitamos primero transformar las imágenes de $28\\times28$ en vectores.\n",
    "\n",
    "Creamos dos nuevas variables para mantener las imágenes originales y su versión \"aplanada\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vector = x_train.reshape(-1, 28 * 28)\n",
    "x_test_vector = x_test.reshape(-1, 28 * 28)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train_vector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que los datos han sido adaptados, podemos intentar abordar el problema con modelos de aprendizaje automático clásicos.\n",
    "\n",
    "Para ver que métrica es más adecuada, analizamos antes cuantas imágenes hay de cada número (clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=y_train, hue=map(str, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso las clases están bastante balanceadas, por lo que la `f1 macro` será suficiente. \n",
    "\n",
    "Ten en cuenta que los métodos que no son baselines tardarán algo de tiempo en entrenar, puesto que ahora cada ejemplo se compone de $784$ entradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from tabulate import tabulate\n",
    "    \n",
    "def evaluate_model(Y_test, preds_test, model_name, average=\"binary\"):\n",
    "    preds_test = (preds_test >= 0.5).astype(int)\n",
    "    metrics = [\n",
    "        (\"Accuracy\", accuracy_score(Y_test, preds_test)),\n",
    "        (\"F1\", f1_score(Y_test,preds_test, average=average))\n",
    "    ]\n",
    "    \n",
    "    print(f\"Resultados para {model_name}:\")\n",
    "    print(tabulate(metrics, headers=[\"Métrica\", \"TEST\"], tablefmt=\"rounded_outline\"))\n",
    "    print()\n",
    "    \n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy=\"uniform\")\n",
    "baseline_random.fit(x_train_vector, y_train)\n",
    "preds_test = baseline_random.predict(x_test_vector)\n",
    "evaluate_model(y_test, preds_test, \"Baseline Random\", average=\"macro\")\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline_zero.fit(x_train_vector, y_train)\n",
    "preds_test = baseline_zero.predict(x_test_vector)\n",
    "evaluate_model(y_test, preds_test, \"Baseline Zero-R\", average=\"macro\")\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(x_train_vector, y_train)\n",
    "preds_test = model_knn.predict(x_test_vector)\n",
    "evaluate_model(y_test, preds_test, \"KNN\", average=\"macro\")\n",
    "\n",
    "# Árboles de Decisión\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(x_train_vector, y_train)\n",
    "preds_test = model_tree.predict(x_test_vector)\n",
    "evaluate_model(y_test, preds_test, \"Árbol de decisión\", average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos retorna los siguientes resultados:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo            | Accuracy (Test) | F1 (Test) |\n",
    "|-------------------|-----------------|-----------|\n",
    "| Baseline Random   | 0.114           | 0.032     |\n",
    "| Baseline Zero-R   | 0.114           | 0.020     |\n",
    "| KNN               | 0.211           | 0.120     |\n",
    "| Árbol de decisión | 0.202           | 0.112     |\n",
    "\n",
    "</center>\n",
    "\n",
    "### **3.3 Aprendizaje profundo**\n",
    "\n",
    "Vamos a crear dos opciones, una *red totalmente conectada* que reciba el vector de $784$ números, y a continuación una *red convolucional* que reciba directamente las imágenes.\n",
    "\n",
    "Antes de continuar necesitaremos codificar correctamente las salidas esperadas $Y$ de nuestro modelo.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Codifica y sobrescribe las Y utilizando one-hot.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Red totalmente conectada**\n",
    "\n",
    "Vamos a fijar previamente las semillas del `tensorflow` y crear de nuevo la función auxiliar `plot_loss_history()` para ver la evolución de la loss durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "\n",
    "# Fijar las semillas de las librerías para que los resultados se repitan.\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "def plot_loss_history(history):\n",
    "    # Extraer los datos del historial\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', None)  # Puede no existir si no se usó validación\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Crear un DataFrame para seaborn\n",
    "    data = pd.DataFrame({ 'Epoch': list(epochs) * 2, 'Loss': loss + (val_loss if val_loss else []), 'Type': ['Train'] * len(loss) + (['Validation'] * len(val_loss) if val_loss else []) })\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=data, x=\"Epoch\", y=\"Loss\", hue=\"Type\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Evolución de la loss durante el entrenamiento\")\n",
    "    plt.legend(title=\"Conjunto\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea una <i>red totalmente contectada</i> para resolver este problema y rellena la tabla. Ajusta los hiperparámetros si lo deseas.\n",
    "</div>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo            | Accuracy (Test) | F1 (Test) |\n",
    "|-------------------|-----------------|-----------|\n",
    "| Baseline Random   | 0.114           | 0.032     |\n",
    "| Baseline Zero-R   | 0.114           | 0.020     |\n",
    "| KNN               | 0.211           | 0.120     |\n",
    "| Árbol de decisión | 0.202           | 0.112     |\n",
    "| Red Neuronal      |                 |           |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def red_fully_connected(learning_rate):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Tu código aquí\n",
    "\n",
    "    optim = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='', optimizer=optim)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_fcn = red_fully_connected(learning_rate = 0.0005)\n",
    "\n",
    "# Ver el summary\n",
    "model_fcn.summary()\n",
    "\n",
    "# Entrenamos\n",
    "history = model_fcn.fit(x_train_vector, y_train, validation_split=0.2, batch_size=256, epochs=20, verbose=2)\n",
    "\n",
    "# Visualizamos\n",
    "plot_loss_history(history)\n",
    "\n",
    "# Evaluar en test\n",
    "preds_test = model_fcn.predict(x_test_vector)\n",
    "evaluate_model(y_test, preds_test, \"Red neuronal\", average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Red convolucional**\n",
    "\n",
    "A continuación se te proporciona la arquitectura de una red convolucional pensada para resolver este problema.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Completa el <i>tamaño de la entrada</i>, la <i>función de activación de la última capa</i> y la <i>función de pérdida</i>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def red_convolucional(learning_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=()))  # Entrada como imagen en escala de grises\n",
    "\n",
    "    # EXTRACTOR DE CARACTERÍSTICAS -------------------------------------------\n",
    "    # Primer bloque de convolución y max pooling\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Segundo bloque de convolución y max pooling\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Tercer bloque de convolución y max pooling\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # PARTE TOTALMENTE CONECTADA ---------------------------------------------\n",
    "    # Aplanar y capas densas finales\n",
    "    model.add(Flatten()) # Este vector es el que aprende la red durante el entrenamiento y le sirve para representar a cada imagen\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(10, activation='', name=\"output_layer\"))\n",
    "\n",
    "    optim = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss='', optimizer=optim)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_cnn = red_convolucional(learning_rate = 0.0005)\n",
    "\n",
    "# Ver el summary\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente entrenamos y evaluamos en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos\n",
    "history = model_cnn.fit(x_train, y_train, validation_split=0.2, batch_size=128, epochs=20, verbose=2)\n",
    "\n",
    "# Visualizamos\n",
    "plot_loss_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Añade el código necesario para evaluar tu modelo y rellena la tabla.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo            | Accuracy (Test) | F1 (Test) |\n",
    "|-------------------|-----------------|-----------|\n",
    "| Baseline Random   | 0.114           | 0.032     |\n",
    "| Baseline Zero-R   | 0.114           | 0.020     |\n",
    "| KNN               | 0.211           | 0.120     |\n",
    "| Árbol de decisión | 0.202           | 0.112     |\n",
    "| Red Neuronal      |                 |           |\n",
    "| Red Convolucional |                 |           |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **4. Ejercicios**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Crear un modelo que dada la imagen de un dígito, prediga si <u>es un cuatro o un nueve.</u></b> Ya se proporciona el código encargado de crear el dataset necesario.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Cargamos el dataset MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "def filter_and_relabel(x, y, class_pos=1, class_neg=7):\n",
    "    # Filtramos solo los dígitos deseados\n",
    "    idx = np.where((y == class_pos) | (y == class_neg))[0]\n",
    "    x_filtered = x[idx]\n",
    "    y_filtered = y[idx]\n",
    "\n",
    "    # Etiquetamos: 1 si es class_pos, 0 si es class_neg\n",
    "    y_binary = (y_filtered == class_pos).astype(np.uint8)\n",
    "\n",
    "    # Balanceamos (debería estar casi balanceado ya)\n",
    "    idx_pos = np.where(y_binary == 1)[0]\n",
    "    idx_neg = np.where(y_binary == 0)[0]\n",
    "\n",
    "    n = min(len(idx_pos), len(idx_neg))\n",
    "    np.random.seed(42)\n",
    "    idx_pos_sampled = np.random.choice(idx_pos, size=n, replace=False)\n",
    "    idx_neg_sampled = np.random.choice(idx_neg, size=n, replace=False)\n",
    "\n",
    "    idx_total = np.concatenate([idx_pos_sampled, idx_neg_sampled])\n",
    "    np.random.shuffle(idx_total)\n",
    "\n",
    "    return x_filtered[idx_total], y_binary[idx_total]\n",
    "\n",
    "# Aplicamos para train y test\n",
    "x_train, y_train = filter_and_relabel(x_train, y_train, class_pos=4, class_neg=9)\n",
    "x_test, y_test = filter_and_relabel(x_test, y_test, class_pos=4, class_neg=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
