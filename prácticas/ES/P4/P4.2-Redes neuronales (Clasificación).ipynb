{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Práctica 4.2: Redes neuronales (Clasificación)**\n",
    "\n",
    "<hr>\n",
    "\n",
    "## **1. Introducción**\n",
    "En la práctica anterior aprendimos a resolver problemas de regresión con redes neuronales. En esta práctica, exploraremos la resolución de **problemas de clasificación**.\n",
    "\n",
    "Hasta ahora, nos hemos centrado en problemas de clasificación binaria pero en esta práctica abordaremos también dos nuevos tipos.\n",
    "\n",
    "### **Objetivos**\n",
    "En esta práctica aprenderás a:\n",
    "* Distinguir entre tipos de problemas de clasificación.\n",
    "* Modificar una red neuronal para aprender problemas de clasificación.\n",
    "* Transformar variables categoricas en numéricas.\n",
    "\n",
    "Comenzamos cargando una vez más nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seed = 2533\n",
    "data = pd.read_pickle(\"https://raw.githubusercontent.com/AIC-Uniovi/Sistemas-Inteligentes/refs/heads/main/datasets/f1_23_monaco.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **2. Problemas de clasificación binaria**\n",
    "\n",
    "Vamos a intentar resolver un problema similar al de la práctica 3 de clasificación, es decir: \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Crear un modelo que, dado el tiempo (en segundos) de los dos primeros sectores de un piloto de <i>Aston Martin</i> (<code>\"Sector1Time\", \"Sector2Time\"</code>), se prediga si ese tiempo lo realizó <i>Alonso</i> o no (<i>Stroll</i>).</b>\n",
    "</div>\n",
    "\n",
    "Como siempre, lo primero será crear los datasets necesarios para entrenar un modelo.\n",
    "\n",
    "### **2.1. Preprocesado de datos**\n",
    "\n",
    "Creamos la variable <code>data_aston</code> con las filas y columnas necesarias para entrenar nuestros modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aston = data.loc[data.Team==\"Aston Martin\"][[\"Sector1Time\", \"Sector2Time\", \"Driver\"]].copy()\n",
    "data_aston[\"Sector1Time\"] = data_aston[\"Sector1Time\"].dt.total_seconds()\n",
    "data_aston[\"Sector2Time\"] = data_aston[\"Sector2Time\"].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea la columna <code>Class</code> dentro del DataFrame <code>data_aston</code> para que valga cero siempre que el piloto no sea Alonso y 1 en el caso contrario. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa las X e Y del dataframe <code>data_aston</code> , divide en entrenamiento y test (80/20) fijando la semilla y finalmente <b>estandariza</b> las X.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2. Aprendizaje automático**\n",
    "\n",
    "Con los datos listos, entrenaremos y evaluaremos de nuevo los modelos de aprendizaje automático ya conocidos para poder compararlos con nuestro nuevo sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Entrena y evalúa los modelos restantes (<i>Regresión Logística</i>, <i>K-Nearest Neighbors</i>, <i>Árboles de decisión</i> y <i>SVC</i>) utilizando la siguiente función.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tabulate import tabulate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def evaluate_model(Y_test, preds_test, model_name, average=\"binary\"):\n",
    "    preds_test = (preds_test >= 0.5).astype(int)\n",
    "    metrics = [\n",
    "        (\"Accuracy\", accuracy_score(Y_test, preds_test)),\n",
    "        (\"F1\", f1_score(Y_test,preds_test, average=average))\n",
    "    ]\n",
    "    \n",
    "    print(f\"Resultados para {model_name}:\")\n",
    "    print(tabulate(metrics, headers=[\"Métrica\", \"TEST\"], tablefmt=\"rounded_outline\"))\n",
    "    print()\n",
    "\n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy=\"uniform\")\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "preds_test = baseline_random.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline Random\")\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline_zero.fit(X_train, Y_train)\n",
    "preds_test = baseline_zero.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline Zero-R\")\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados han de ser algo así:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                | Accuracy (test) | F1 (test) |\n",
    "|-----------------------|-----------------|-----------|\n",
    "| Baseline Random       | 0.522           | 0.560     |\n",
    "| Baseline Zero-R       | 0.565           | 0.722     |\n",
    "| Regresión Logística   | 0.565           | 0.722     |\n",
    "| KNN                   | 0.957           | 0.963     |\n",
    "| Árboles de Decisión   | 0.826           | 0.867     |\n",
    "| SVC                   | 0.913           | 0.929     |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Visualizar datos y modelos**\n",
    "\n",
    "En este caso, nuestro problema tiene dos entradas y una salida (la clase). Como ya vimos en la parte de regresión, trabajar con tan pocas dimensiones nos permite visualizar el comportamiento de los datos y de los modelos que estamos aprendiendo.\n",
    "\n",
    "Gracias a esta posibilidad, podemos analizar de antemano si la relación entre las entradas y salidas puede resolverse con modelos lineales o, por el contrario, requiere de un enfoque no lineal.\n",
    "\n",
    "A continuación te proporcionamos la función que visualiza los datos y, dado un modelo, realiza una serie de predicciones para dibujar su **frontera de decisión**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Función para visualizar los datos y la frontera de decisión del modelo\n",
    "def plot_decision_boundary(X_train, Y_train, X_test, Y_test, model, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Crear una malla de puntos en el rango de los datos de Train y Test\n",
    "    x_min, x_max = min(X_train[:, 0].min(), X_test[:, 0].min()) - 0.5, max(X_train[:, 0].max(), X_test[:, 0].max()) + 0.5\n",
    "    y_min, y_max = min(X_train[:, 1].min(), X_test[:, 1].min()) - 0.5, max(X_train[:, 1].max(), X_test[:, 1].max()) + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    # Predecir la probabilidad para cada punto de la malla\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = model.predict(grid).reshape(xx.shape)\n",
    "\n",
    "    # Dibujar la frontera de decisión\n",
    "    contour = plt.contourf(xx, yy, Z, levels=[0, 0.5, 1], alpha=0.7, cmap=\"coolwarm\")\n",
    "\n",
    "    # Añadir colorbar\n",
    "    plt.colorbar(contour)\n",
    "\n",
    "    # Visualizar los puntos de Train\n",
    "    plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train, cmap=\"coolwarm\", edgecolors=\"k\", label=\"Train Data\")\n",
    "    \n",
    "    # Visualizar los puntos de Test\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test, cmap=\"coolwarm\", marker=\"X\", label=\"Test Data\")\n",
    "\n",
    "    # Etiquetas y leyenda\n",
    "    plt.xlabel(\"Sector1Time\")\n",
    "    plt.ylabel(\"Sector1Time\")\n",
    "    plt.title(f\"Frontera de decisión: {model_name}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(X_train, Y_train, X_test, Y_test, baseline_random, \"Baseline Aleatorio\")\n",
    "plot_decision_boundary(X_train, Y_train, X_test, Y_test, baseline_zero, \"Baseline Zero-R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Dibuaja la frontera de decisión para el resto de modelos y trata de entender los resultados.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> ¿Crees que el problema es lineal o no lineal? Analizando las fronteras de decisión, ¿qué modelos son no lineales?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tu respuesta aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3. Red neuronal**\n",
    "\n",
    "Crearemos ahora una red neuronal desde cero para resolver este problema. Recuerda que los pasos son los siguientes:\n",
    "\n",
    "1) Crear la arquitectura del modelo.\n",
    "2) Detallar el optimizador, la función de pérdida y compilar.\n",
    "3) Entrenar y evaluar.\n",
    "\n",
    "Vamos a fijar las semillas y crear la función para dibujar la evolución del entrenamiento del modelo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "\n",
    "# Fijar las semillas de las librerías para que los resultados se repitan.\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "def plot_loss_history(history):\n",
    "    # Extraer los datos del historial\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', None)  # Puede no existir si no se usó validación\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    # Crear un DataFrame para seaborn\n",
    "    data = pd.DataFrame({ 'Epoch': list(epochs) * 2, 'Loss': loss + (val_loss if val_loss else []), 'Type': ['Train'] * len(loss) + (['Validation'] * len(val_loss) if val_loss else []) })\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=data, x=\"Epoch\", y=\"Loss\", hue=\"Type\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Evolución de la loss durante el Entrenamiento\")\n",
    "    plt.legend(title=\"Conjunto\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Activación en la última capa y loss**\n",
    "\n",
    "Como se mencionó en la práctica anterior, al crear una red neuronal es crucial seleccionar adecuadamente tanto la **función de activación de la última capa** como la **función de pérdida**.\n",
    "\n",
    "En un problema de regresión, la última capa generalmente no utiliza una función de activación para evitar que las predicciones se limiten a un rango específico. Sin embargo, si los valores que se intentan predecir son siempre positivos, se podría aplicar una función *ReLU*.\n",
    "\n",
    "<center>\n",
    "    <div style=\"border-radius:5px; padding:10px; background:white; max-width:900px\">\n",
    "        <img src=\"https://i.imgur.com/e7kd5fs.png\">   \n",
    "    </div>\n",
    "</center>\n",
    "\n",
    "Nos enfrentamos ahora a un problema de **clasificación binaria**, donde buscamos predecir una probabilidad, es decir, un valor comprendido entre $0$ y $1$. Por consiguiente, debemos emplear una función **sigmoide** como función de activación en la capa final.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Recuerda que una red neuronal que <b>solo</b> tiene una función de activación en la última capa <b>no puede aprender problemas no lineales</b>; para eso se requieren funciones de activación en las capas ocultas.\n",
    "</div>\n",
    "\n",
    "Otro elemento que tenemos que cambiar respecto de los problemas de regresión es la **función de pérdida** o loss. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> En un problema de clasificación binaria, no se deben usar funciones de pérdida diseñadas para regresión, como el <b>error absoluto medio</b> (MAE), ya que están orientadas a problemas donde las salidas <b>son valores continuos y no probabilidades</b>.\n",
    "</div>\n",
    "\n",
    "Por tanto, además de añadir una sigmoide a la capa de salida, tendremos también que cambiar la función de pérdida a **Binary Crossentropy**. Lo que nos deja con la siguiente tabla: \n",
    "\n",
    "<center>\n",
    "\n",
    "| Tipo de problema              | Función de activación en la última capa         | Función de pérdida    | En *keras*                                  |\n",
    "|-------------------------------|-------------------------------------------------|-----------------------|---------------------------------------------|\n",
    "| *Regresión*                   | Ninguna o *ReLU* (si los valores son positivos) | *MAE* o *MSE*         | `mean_average_error` o `mean_squared_error` |\n",
    "| *Clasificación Binaria*       | *Sigmoide*                                      | *Binary Crossentropy* | `binary_crossentropy`                       |\n",
    "\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea, dentro de la función proporcionada, una red neuronal de <b>clasificación binaria</b> con una sola capa. Entrena, dibuja la evolución de la loss utilizando la función <code>plot_loss_history</code> y analiza su frontera de decisión.\n",
    "    <hr>\n",
    "    Entrena con un conjunto de validación del 20%, durante 300 epochs, con un tamaño de batch de 16 y un learning rate de 0,005.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_neuronal_uno(learning_rate):\n",
    "    # Creamos y compilamos el modelo\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_1 = red_neuronal_uno(learning_rate = 0.005)\n",
    "\n",
    "# Entrenamos\n",
    "# Tu código aquí\n",
    "\n",
    "# Visualizar entrenamiento\n",
    "# Tu código aquí\n",
    "\n",
    "# Frontera de decisión\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Evalúa el modelo anterior en Test utilizando <code>.predict()</code> y <code>evaluate_model</code>. Añade el resultado a la tabla.\n",
    "    <hr>\n",
    "    En este caso <b>no</b> vamos a intentar buscar los mejores hiperparámetros; como has visto, este modelo es lineal y no va a ser capaz de resolver nuestro problema no lineal.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                | Accuracy (test) | F1 (test) |\n",
    "|-----------------------|-----------------|-----------|\n",
    "| Baseline Random       | 0.522           | 0.560     |\n",
    "| Baseline Zero-R       | 0.565           | 0.722     |\n",
    "| Regresión Logística   | 0.565           | 0.722     |\n",
    "| KNN                   | 0.957           | 0.963     |\n",
    "| Árboles de Decisión   | 0.826           | 0.867     |\n",
    "| SVC                   | 0.913           | 0.929     |\n",
    "| Red Neuronal Lineal   |                 |           |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea una red neuronal <u>no lineal</u> de clasificación binaria y busca el mejor learning rate. Entrena el modelo final con el mejor hiperparámetro y evalúa en test. Rellena ambas tablas.\n",
    "    <hr>\n",
    "    Fija el conjunto de validación al 20%, las epocas a 500 y el batch a 16. Para entrenar el modelo final no es necesario el conjunto de validación.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Visualiza también la frontera de decisión verificando que el modelo aprendido es no lineal.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "| Modelo                     | Loss (train)  | Loss (val) |\n",
    "|----------------------------|---------------|------------|\n",
    "| *Red Neuronal (lr=0.001)*  |               |            |\n",
    "| *Red Neuronal (lr=0.005)*  |               |            |\n",
    "| *Red Neuronal (lr=0.01)*   |               |            |\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                 | Accuracy (test) | F1 (test) |\n",
    "|------------------------|-----------------|-----------|\n",
    "| Baseline Random        | 0.522           | 0.560     |\n",
    "| Baseline Zero-R        | 0.565           | 0.722     |\n",
    "| Regresión Logística    | 0.565           | 0.722     |\n",
    "| KNN                    | 0.957           | 0.963     |\n",
    "| Árboles de Decisión    | 0.826           | 0.867     |\n",
    "| SVC                    | 0.913           | 0.929     |\n",
    "| Red Neuronal Lineal    |                 |           |\n",
    "| Red Neuronal No Lineal |                 |           |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_neuronal_dos(learning_rate):\n",
    "    # Creamos y compilamos el modelo\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_2 = red_neuronal_dos(learning_rate = 0.001)\n",
    "\n",
    "# Entrenamos\n",
    "# Tu código aquí\n",
    "\n",
    "# Visualizar entrenamiento\n",
    "# Tu código aquí\n",
    "\n",
    "# Repetir para otro valor del hiperparámetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo final (sin validación)\n",
    "# Tu código aquí\n",
    "\n",
    "# Evaluar en test\n",
    "# Tu código aquí\n",
    "\n",
    "# Frontera de decisión\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Entra en la siguiente web para visualizar en entrenamiento y frontera de decisión de una red neuronal para diferentes problemas de clasificación binaria: <a href=\"https://playground.tensorflow.org/\">https://playground.tensorflow.org/</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **3. Problemas de multiclasificación**\n",
    "\n",
    "Hasta ahora, nuestros problemas de clasificación siempre se han centrado en la clasificación binaria, pero como sabes, existen más tipos de problemas de este tipo.\n",
    "\n",
    "Vamos a intentar resolver ahora un problema **multiclase**, es decir, un problema donde cada ejemplo puede pertenecer **a una entre varias clases posibles**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Crear un modelo que, dado el tiempo (en segundos) de los sectores (<code>\"Sector1Time\", \"Sector2Time\" y \"Sector3Time\"</code>), las velocidades (<code>\"SpeedI1\", \"SpeedI2\", \"SpeedFL\" y \"SpeedST\"</code>) y los datos del neumático (<code>\"Compound\" y \"TyreLife\"</code>) sea capaz de predecir el <i>equipo</i> (<code>\"Team\"</code>) del coche que realizó dicha vuelta.</b> \n",
    "</div>\n",
    "  \n",
    "Como siempre, lo primero será crear los datasets necesarios para entrenar un modelo.\n",
    "\n",
    "### **3.1. Preprocesado de datos**\n",
    "\n",
    "Creamos la variable <code>data_teams</code> con las filas y columnas necesarias para entrenar nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_cols = [\"Sector1Time\", \"Sector2Time\", \"Sector3Time\", \"SpeedI1\", \"SpeedI2\", \"SpeedFL\", \"SpeedST\", \"Compound\", \"TyreLife\", \"Team\"]\n",
    "data_teams = data[relevant_cols].copy()\n",
    "data_teams = data_teams.dropna().reset_index(drop=True) # Eliminamos las filas con algún valor nulo\n",
    "\n",
    "data_teams[\"Sector1Time\"] = data_teams[\"Sector1Time\"].dt.total_seconds()\n",
    "data_teams[\"Sector2Time\"] = data_teams[\"Sector2Time\"].dt.total_seconds()\n",
    "data_teams[\"Sector3Time\"] = data_teams[\"Sector3Time\"].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea un <code>countplot()</code> de la columna <code>\"Team\"</code> del DataFrame <code>data_teams</code> para ver si existe desbalanceo de clases. ¿Crees que lo hay?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "\n",
    "# Tu código aquí\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Categórico a numérico**\n",
    "\n",
    "A continuación tenemos que codificar **de forma numérica** todas aquellas columnas que sean de tipo *texto* o *categóricas*.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Recuerda que un modelo no puede trabajar con texto, ni a la entrada ni a la salida.\n",
    "</div>\n",
    "\n",
    "Si la columna que intentamos transformar a número solo toma dos valores ('Si' o 'No', 'Alonso' o 'Stroll', 'Enfermo' o 'No enfermo', ...), podemos realizar el mismo truco de prácticas anteriores: asignar un $1$ a un valor y $0$ al contrario.\n",
    "\n",
    "El problema viene en aquellas columnas donde el modelo puede tomar múltiples valores como la variable `Compound` de la entrada o la variable objetivo `Team`. Para codificar estas se utiliza un método conocido como **One-Hot** o, si cada columna puede tener más de un valor, **Multi-Label Binarization**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Utiliza el método <code>pd.get_dummies()</code> de <code>pandas</code> pasando <code>data_teams</code> como parámetro, ¿Qué sucede?.\n",
    "    <hr>\n",
    "    Cuando lo entiendas, sobreescribe <code>data_teams</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa las X e Y del dataframe <code>data_teams</code>, divide en entrenamiento y test (80/20) fijando la semilla y finalmente <b>normaliza</b> con la clase <code>MinMaxScaler()</code> las X.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_cols = ['Sector1Time', 'Sector2Time', 'Sector3Time', 'SpeedI1', 'SpeedI2', 'SpeedFL', 'SpeedST', 'TyreLife', 'Compound_HARD', 'Compound_INTERMEDIATE', 'Compound_MEDIUM', 'Compound_SOFT', 'Compound_WET']\n",
    "y_cols = ['Team_Alfa Romeo', 'Team_AlphaTauri', 'Team_Alpine', 'Team_Aston Martin', 'Team_Ferrari', 'Team_Haas F1 Team', 'Team_McLaren', 'Team_Mercedes', 'Team_Red Bull Racing', 'Team_Williams']\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.2. Aprendizaje automático**\n",
    "\n",
    "Con los datos listos, entrenaremos y evaluaremos de nuevo los modelos de aprendizaje automático ya conocidos para poder compararlos con nuestro nuevo sistema.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> La métrica <code>f1_score</code> se puede obtener de diferentes formas en problemas con múltiples clases:\n",
    "    <ul>\n",
    "        <li><strong>micro</strong>: Calcula la métrica global considerando todas las muestras, sin distinguir entre clases. Es útil cuando las clases están desbalanceadas.</li>\n",
    "        <li><strong>macro</strong>: Calcula la métrica de cada clase por separado y luego hace el promedio aritmético. Da el mismo peso a todas las clases, sin importar su frecuencia.</li>\n",
    "        <li><strong>weighted</strong>: Similar a macro, pero pondera cada clase según su número de muestras. Es útil cuando las clases están desbalanceadas.</li>\n",
    "        <li><strong>samples</strong>: Se usa en problemas multietiqueta, calculando la métrica para cada muestra y luego promediando.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "Como ya has visto en el histograma anterior, las clases están balanceadas, por lo que podemos utilizar `macro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy=\"uniform\")\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "preds_test = baseline_random.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline Random\", average=\"macro\")\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline_zero.fit(X_train, Y_train)\n",
    "preds_test = baseline_zero.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline Zero-R\", average=\"macro\")\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train, Y_train)\n",
    "preds_test = model_knn.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"KNN\", average=\"macro\")\n",
    "\n",
    "# Árboles de Decisión\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, Y_train)\n",
    "preds_test = model_tree.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Tree\", average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados han de ser algo así:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo              | Accuracy (test) | F1 macro (test) |\n",
    "|---------------------|-----------------|-----------------|\n",
    "| Baseline Random     | 0.004           | 0.164           |\n",
    "| Baseline Zero-R     | 0.000           | 0.000           |\n",
    "| KNN                 | 0.435           | 0.540           |\n",
    "| Árboles de Decisión | 0.539           | 0.541           |\n",
    "\n",
    "</center>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Como verás, no estamos utilizando modelos como la <b>Regresión Logística</b> o las <b>Máquinas de vectores soporte</b>. Estos modelos <u>solo funcionan para resolver problemas de clasificación binaria</u>, aunque existen formas de adaptarlos a problemas multiclase. \n",
    "</div>\n",
    "\n",
    "### **3.3. Aprendizaje profundo**\n",
    "\n",
    "Una vez tenemos varios modelos de aprendizaje automático entrenados para resolver nuestro problema, intentaremos crear una *red neuronal* con el objetivo de mejorar los resultados.\n",
    "\n",
    "Al ser un problema de clasificación, buscamos obtener valores entre $0$ y $1$ en la salida (probabilidades), por lo que podemos pensar que es necesario ubicar una `sigmoid` en la última capa.\n",
    "\n",
    "El problema radica en que, en la clasificación multiclase, tenemos tantas salidas como clases, pero **solo una de ellas puede valer uno**, ya que cada ejemplo pertenece a una única clase.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Si utilizamos una función <code>sigmoid</code> en la capa final de un modelo con múltiples salidas, cada salida tendrá un valor entre cero y uno, lo que <b>no garantiza que <u>solo una</u> de las salidas tenga un valor de uno</b>.\n",
    "</div>\n",
    "\n",
    "Como ves, la `sigmoid` no es buena opción en este caso, es por eso en este tipo de problemas utilizaremos la `softmax`.\n",
    "\n",
    "También será necesario utilizar una *función de pérdida* que tenga en cuenta este escenario multiclase. Esta es la llamada `Categorical Crossentropy`.\n",
    "\n",
    "Actualizando nuestra tabla de *cambios* en redes neuronales según el problema, obtenemos lo siguiente:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Tipo de problema              | Función de activación en la última capa         | Función de pérdida         | En *keras*                                  |\n",
    "|-------------------------------|-------------------------------------------------|----------------------------|---------------------------------------------|\n",
    "| *Regresión*                   | Ninguna o *ReLU* (si los valores son positivos) | *MAE* o *MSE*              | `mean_average_error` o `mean_squared_error` |\n",
    "| *Clasificación Binaria*       | *Sigmoide*                                      | *Binary Crossentropy*      | `binary_crossentropy`                       |\n",
    "| *Clasificación Multiclase*    | *Softmax*                                       | *Categorical Crossentropy* | `categorical_crossentropy`                  |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea una red neuronal de multiclasificación no lineal para intentar mejorar los modelos de aprendizaje automático tradicionales en esta tarea. Busca el mejor <code>learning rate</code>, entrena y evalúa en test el modelo final. Rellena ambas tablas.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Fija el conjunto de validación al 20%, las epocas a 200 y el batch a 64. Recuerda que para entrenar el modelo final no es necesario el conjunto de validación.\n",
    "</div>\n",
    "\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                     | Loss (train)  | Loss (val) |\n",
    "|----------------------------|---------------|------------|\n",
    "| *Red Neuronal (lr=0.001)*  |               |            |\n",
    "| *Red Neuronal (lr=0.005)*  |               |            |\n",
    "| *Red Neuronal (lr=0.01)*   |               |            |\n",
    "\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo              | Accuracy (test) | F1 macro (test) |\n",
    "|---------------------|-----------------|-----------------|\n",
    "| Baseline Random     | 0.004           | 0.164           |\n",
    "| Baseline Zero-R     | 0.000           | 0.000           |\n",
    "| KNN                 | 0.435           | 0.540           |\n",
    "| Árboles de Decisión | 0.539           | 0.541           |\n",
    "| Red Neuronal        |                 |                 |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_neuronal_multiclass(learning_rate):\n",
    "    # Creamos y compilamos el modelo\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_mtc = red_neuronal_multiclass(learning_rate = 0.001)\n",
    "\n",
    "# Entrenamos\n",
    "# Tu código aquí\n",
    "\n",
    "# Visualizamos el entrenamiento\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo final (sin validación)\n",
    "# Tu código aquí\n",
    "\n",
    "# Evaluar en test\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **4. Problemas multietiqueta**\n",
    "\n",
    "El último tipo de problema que nos queda por ver es la clasificación **multietiqueta**, es decir, un problema donde cada ejemplo puede pertenecer **a una o varias clases**.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Desarrolla un modelo que, dado el tipo de neumático y la velocidad en el primer sector (<code>\"Compound\" y \"SpeedI1\"</code>), pueda predecir el <i>piloto o pilotos</i> (<code>\"Driver\"</code>) que han utilizado dicha combinación.</b>\n",
    "</div>\n",
    "  \n",
    "Como siempre, lo primero será crear el dataset necesario para entrenar y evaluar los diferentes modelos.\n",
    "\n",
    "### **4.1. Preprocesado de datos**\n",
    "\n",
    "Creamos la variable <code>data_drivers</code> con las filas y columnas necesarias para entrenar nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "data_drivers = data.groupby([\"Compound\",\"SpeedI1\"])[\"Driver\"].apply(lambda x: x.unique()).reset_index()\n",
    "# Se codifican los pilotos como multi-hot\n",
    "mlb = MultiLabelBinarizer()\n",
    "driver_dummies = pd.DataFrame(mlb.fit_transform(data_drivers[\"Driver\"]), columns=map(lambda x: \"Driver_\"+str(x),mlb.classes_))\n",
    "# Se añaden las nuevas columnas codificadas como números\n",
    "data_drivers = data_drivers = pd.concat([data_drivers.drop(columns=[\"Driver\"]), driver_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Separa las X e Y del dataframe <code>data_drivers</code>, divide en entrenamiento y test (80/20) fijando la semilla y finalmente <b>normaliza</b> con la clase <code>MinMaxScaler()</code> las X.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Puede que tengas que codificar alguna de las columnas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2. Aprendizaje automático**\n",
    "\n",
    "Con los datos listos, entrenaremos y evaluaremos los modelos de aprendizaje automático ya conocidos para poder compararlos con nuestro nuevo sistema.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Recuerda que la métrica <code>f1_score</code> se puede obtener de diferentes formas en problemas con múltiples clases. En este caso <code>samples</code> parece la mejor opción.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Baseline Random\n",
    "baseline_random = DummyClassifier(strategy=\"uniform\")\n",
    "baseline_random.fit(X_train, Y_train)\n",
    "preds_test = baseline_random.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline Random\", average=\"samples\")\n",
    "\n",
    "# Baseline Zero-R\n",
    "baseline_zero = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline_zero.fit(X_train, Y_train)\n",
    "preds_test = baseline_zero.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Baseline Zero-R\", average=\"samples\")\n",
    "\n",
    "# KNN\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train, Y_train)\n",
    "preds_test = model_knn.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"KNN\", average=\"samples\")\n",
    "\n",
    "# Árboles de Decisión\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, Y_train)\n",
    "preds_test = model_tree.predict(X_test)\n",
    "evaluate_model(Y_test, preds_test, \"Tree\", average=\"samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados han de ser algo así:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo              | Accuracy (test) | F1 samples (test) |\n",
    "|---------------------|-----------------|-------------------|\n",
    "| Baseline Random     | 0.000           | 0.206             | \n",
    "| Baseline Zero-R     | 0.000           | 0.000             |\n",
    "| KNN                 | 0.143           | 0.452             |\n",
    "| Árboles de Decisión | 0.190           | 0.487             |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.3. Aprendizaje profundo**\n",
    "\n",
    "Como siempre, una vez tenemos varios modelos de aprendizaje automático entrenados para resolver nuestro problema, intentaremos crear una *red neuronal* con el objetivo de mejorar los resultados.\n",
    "\n",
    "Como recordarás, en los problemas multiclase teníamos varias salidas (tantas como clases) y cada ejemplo solo podía pertenecer a una clase. En los problemas de **clasificación multietiqueta** como este, también tenemos tantas salidas como clases pero ahora <u>un ejemplo puede pertenecer a una o varias clases</u>. \n",
    "\n",
    "En lo que respecta a nuestra red neuronal, esto implica que podremos tener varios unos a la salida, por tanto podemos utilizar una `sigmoid`. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <strong>Nota:</strong> Los problemas de clasificación multietiqueta se pueden ver como <i>múltiples problemas de clasificación binaria en paralelo</i>.\n",
    "</div>\n",
    "\n",
    "Utilizaremos por tanto la misma loss y función de activación en la última capa que en clasificación binaria. Actualizando nuestra tabla de *cambios* en redes neuronales según el problema, obtenemos lo siguiente:\n",
    "\n",
    "<center>\n",
    "\n",
    "| Tipo de problema              | Función de activación en la última capa         | Función de pérdida         | En *keras*                                  |\n",
    "|-------------------------------|-------------------------------------------------|----------------------------|---------------------------------------------|\n",
    "| *Regresión*                   | Ninguna o *ReLU* (si los valores son positivos) | *MAE* o *MSE*              | `mean_average_error` o `mean_squared_error` |\n",
    "| *Clasificación Binaria*       | *Sigmoide*                                      | *Binary Crossentropy*      | `binary_crossentropy`                       |\n",
    "| *Clasificación Multiclase*    | *Softmax*                                       | *Categorical Crossentropy* | `categorical_crossentropy`                  |\n",
    "| *Clasificación Multietiqueta* | *Sigmoide*                                      | *Binary Crossentropy*      | `binary_crossentropy`                       |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Ejercicio:</b> Crea una red neuronal multietiqueta no lineal para intentar mejorar los modelos de aprendizaje automático tradicionales en esta tarea. Busca el mejor <code>learning rate</code>, entrena y evalúa en test el modelo final. Rellena ambas tablas.\n",
    "    <hr style=\"margin-bottom:5px\">\n",
    "    Fija el conjunto de validación al 20%, las epocas a 200 y el batch a 64. Recuerda que para entrenar el modelo final no es necesario el conjunto de validación.\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "\n",
    "| Modelo                     | Loss (train)  | Loss (val) |\n",
    "|----------------------------|---------------|------------|\n",
    "| *Red Neuronal (lr=0.001)*  |               |            |\n",
    "| *Red Neuronal (lr=0.005)*  |               |            |\n",
    "| *Red Neuronal (lr=0.01)*   |               |            |\n",
    "\n",
    "</center>\n",
    "<br>\n",
    "<center>\n",
    "\n",
    "| Modelo              | Accuracy (test) | F1 samples (test) |\n",
    "|---------------------|-----------------|-------------------|\n",
    "| Baseline Random     | 0.000           | 0.206             | \n",
    "| Baseline Zero-R     | 0.000           | 0.000             |\n",
    "| KNN                 | 0.143           | 0.452             |\n",
    "| Árboles de Decisión | 0.190           | 0.487             |\n",
    "| Red Neuronal        |                 |                   |\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_neuronal_multilabel(learning_rate):\n",
    "    # Creamos y compilamos el modelo\n",
    "    \n",
    "    # Tu código aquí\n",
    "\n",
    "    return model\n",
    "\n",
    "# Creamos la red desde cero\n",
    "model_mtl = red_neuronal_multilabel(learning_rate = 0.001)\n",
    "\n",
    "# Entrenamos\n",
    "# Tu código aquí\n",
    "\n",
    "# Visualizamos el entrenamiento\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo final (sin validación)\n",
    "# Tu código aquí\n",
    "\n",
    "# Evaluar en test\n",
    "# Tu código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## **5. Ejercicios**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Crear un modelo que, a partir del tiempo (en segundos) de los sectores (<code>\"Sector1Time\", \"Sector2Time\" y \"Sector3Time\"</code>) y las velocidades (<code>\"SpeedI1\", \"SpeedI2\", \"SpeedFL\" y \"SpeedST\"</code>), pueda predecir el <i>neumático</i> (<code>\"Compound\"</code>) utilizado en la vuelta.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
